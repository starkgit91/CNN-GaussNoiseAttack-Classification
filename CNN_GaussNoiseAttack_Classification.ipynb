{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMvOXuq3RBY9kicp8UMIUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starkgit91/CNN-GaussNoiseAttack-Classification/blob/main/CNN_GaussNoiseAttack_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lXbblgWqkZYP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random as rand"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r'/content/without_attack.csv')\n",
        "print(\"withoutattak file\\n\",df)\n",
        "\n",
        "cnt = df['14'].value_counts()\n",
        "print(cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PQ544izki5l",
        "outputId": "0518d613-ab00-4d00-8331-945478e69f13"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "withoutattak file\n",
            "     Unnamed: 0  0         1         2         3         4         5         6  \\\n",
            "0            0  0  1.005513  1.000230  0.996058  0.994787  0.994405  0.994291   \n",
            "1            1  0  0.990960  0.987148  0.982963  0.981680  0.981295  0.981180   \n",
            "2            2  0  0.951800  0.950249  0.945989  0.944675  0.944281  0.944163   \n",
            "3            3  0  0.967765  0.971844  0.967768  0.966495  0.966112  0.965998   \n",
            "4            4  0  0.963105  0.966423  0.962317  0.961033  0.960647  0.960531   \n",
            "5            5  0  0.944005  0.953005  0.948935  0.947650  0.947263  0.947147   \n",
            "6            6  0  0.981871  0.990865  0.986739  0.985494  0.985119  0.985007   \n",
            "7            7  0  0.983927  0.996208  0.992045  0.990830  0.990462  0.990353   \n",
            "8            8  0  0.969115  0.980292  0.976149  0.974903  0.974527  0.974415   \n",
            "9            9  0  0.956494  0.966900  0.962749  0.961484  0.961103  0.960989   \n",
            "10          10  0  0.938260  0.947112  0.942969  0.941677  0.941287  0.941171   \n",
            "11          11  0  0.950467  0.959343  0.955289  0.954011  0.953626  0.953511   \n",
            "12          12  0  0.917528  0.925149  0.920966  0.919642  0.919244  0.919125   \n",
            "13          13  0  0.928088  0.936246  0.932000  0.930691  0.930296  0.930179   \n",
            "\n",
            "           7         8  ...       320       321       322       323       324  \\\n",
            "0   0.994257  1.004259  ...  0.989217  0.989077  0.989036  1.004424  0.998431   \n",
            "1   0.981145  0.989579  ...  0.976001  0.975861  0.975819  0.989821  0.985280   \n",
            "2   0.944128  0.950265  ...  0.938761  0.938617  0.938574  0.950606  0.948252   \n",
            "3   0.965964  0.966405  ...  0.960876  0.960736  0.960695  0.966619  0.969954   \n",
            "4   0.960497  0.961745  ...  0.955380  0.955239  0.955197  0.961957  0.964520   \n",
            "5   0.947113  0.942516  ...  0.941819  0.941678  0.941635  0.942767  0.950936   \n",
            "6   0.984973  0.980302  ...  0.980049  0.979912  0.979871  0.980624  0.988945   \n",
            "7   0.990320  0.982282  ...  0.985152  0.985018  0.984978  0.982498  0.994158   \n",
            "8   0.974381  0.967554  ...  0.969978  0.969841  0.969800  0.968060  0.978571   \n",
            "9   0.960956  0.954930  ...  0.956286  0.956147  0.956106  0.955386  0.965070   \n",
            "10  0.941136  0.936740  ...  0.935991  0.935849  0.935807  0.937066  0.945097   \n",
            "11  0.953476  0.948928  ...  0.947618  0.947477  0.947435  0.948840  0.956894   \n",
            "12  0.919089  0.916092  ...  0.913590  0.913444  0.913401  0.916265  0.922993   \n",
            "13  0.930143  0.926599  ...  0.925158  0.925014  0.924971  0.926948  0.934298   \n",
            "\n",
            "         325       326       327       328       329  \n",
            "0   0.993940  0.992549  0.992130  0.992005  0.991968  \n",
            "1   0.980773  0.979369  0.978946  0.978820  0.978782  \n",
            "2   0.943665  0.942226  0.941793  0.941663  0.941625  \n",
            "3   0.965567  0.964174  0.963754  0.963628  0.963591  \n",
            "4   0.960098  0.958693  0.958270  0.958143  0.958105  \n",
            "5   0.946556  0.945150  0.944725  0.944598  0.944560  \n",
            "6   0.984521  0.983159  0.982747  0.982624  0.982587  \n",
            "7   0.989705  0.988375  0.987972  0.987851  0.987815  \n",
            "8   0.974133  0.972770  0.972358  0.972234  0.972198  \n",
            "9   0.960618  0.959234  0.958816  0.958691  0.958654  \n",
            "10  0.940643  0.939228  0.938801  0.938673  0.938635  \n",
            "11  0.952530  0.951131  0.950708  0.950581  0.950544  \n",
            "12  0.918490  0.917040  0.916603  0.916472  0.916433  \n",
            "13  0.929737  0.928304  0.927871  0.927742  0.927703  \n",
            "\n",
            "[14 rows x 331 columns]\n",
            "0.990209    1\n",
            "0.976929    1\n",
            "0.939610    1\n",
            "0.961774    1\n",
            "0.956276    1\n",
            "0.942632    1\n",
            "0.980754    1\n",
            "0.986159    1\n",
            "0.970214    1\n",
            "0.956653    1\n",
            "0.936648    1\n",
            "0.948971    1\n",
            "0.914530    1\n",
            "0.925718    1\n",
            "Name: 14, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imbalanced dataset- ML model has to be trained which can accurately predict that which data is fraud and not fraud\n",
        "# we train ML model with logistic regression and supervised learning\n",
        "\n",
        "df = df.sample(frac=1,random_state=1)\n",
        "df = df.reset_index(drop=True)\n",
        "# print(df.head())"
      ],
      "metadata": {
        "id": "biDHM3kZlJgx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file\n",
        "data = pd.read_csv(r'/content/without_attack.csv')\n",
        "\n",
        "# Iterate over each column and add Gaussian noise to each data point\n",
        "for column in data.columns:\n",
        "    noise = rand.normal(0, 0.5, len(data))\n",
        "    data[column] += noise\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "data.to_csv('noisy_data.csv', index=False)\n",
        "new_data = pd.read_csv(r'noisy_data.csv') ###\n",
        "print(\"with gaussian noise file\\n\",new_data)\n",
        "# print(\"bt\\n\",new_data.head())\n",
        "\n",
        "new_data = new_data.sample(frac=1,random_state=1)\n",
        "new_data = new_data.reset_index(drop=True)\n",
        "print(new_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW56dRgklNZB",
        "outputId": "ba4c038a-bccb-40ce-ab9d-051d7eff5eb0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with gaussian noise file\n",
            "     Unnamed: 0         0         1         2         3         4         5  \\\n",
            "0     0.022548  0.731711  1.460631  1.181690  1.506552 -0.269626  0.827906   \n",
            "1     1.045936 -0.672639  1.479753  0.930949  1.620446  0.723002  0.400265   \n",
            "2     2.201014 -0.307470  1.369897  0.799069  1.623284  1.158190  0.788806   \n",
            "3     3.049990  0.171445  1.066309  0.757294  0.582962  1.152191  1.248344   \n",
            "4     3.992112 -0.322329  1.346721  0.627154  2.190766  1.833913  0.649574   \n",
            "5     4.097633 -0.718435  0.689104  0.690743  1.540620  0.576439  0.636848   \n",
            "6     6.255150  0.065140  1.023787  0.549417  1.070653  1.031308  0.633897   \n",
            "7     6.209121 -0.683053  0.166735  0.569135  1.773111  1.447399  0.692987   \n",
            "8     7.822304  0.379923  0.956333  0.944786  0.377043  1.040007  0.342155   \n",
            "9    10.103559  0.253373  1.419676  1.472139  0.859712  0.792344  0.754511   \n",
            "10   10.437838 -0.842521  0.969741 -0.224265  0.364596  0.994792  0.254363   \n",
            "11   11.333699  0.512575  0.844407 -0.103152  0.202188 -0.315183  0.735661   \n",
            "12   11.503851  0.604421  0.821326 -0.057625  0.721021  0.195318  1.089491   \n",
            "13   12.803756  0.178579  0.494271  1.209421  0.481537  0.679365  1.133506   \n",
            "\n",
            "           6         7         8  ...       320       321       322       323  \\\n",
            "0   0.277984  1.264880  0.296933  ...  1.575325  0.070288  1.749439  1.572800   \n",
            "1   0.434335  1.195689  0.175256  ...  0.910945  1.925933  1.258861  1.351098   \n",
            "2   0.821856  0.604827  1.870345  ...  0.587348  1.954531  0.506248  0.805298   \n",
            "3   0.772380  1.243951  1.304503  ...  1.153243  0.937050  0.847393  0.734659   \n",
            "4   0.473964  0.582532  0.483252  ...  0.261437 -0.118438  0.607778  0.990226   \n",
            "5   1.067320  2.049586  1.265614  ...  0.209931  1.167336  0.456188  1.041420   \n",
            "6   0.884055  0.774053  1.092351  ...  0.274626  0.201940  0.778140  1.174839   \n",
            "7   2.377130  0.502524  1.642669  ...  0.821163  1.480870  1.029034  0.740215   \n",
            "8   0.923363  0.533372  0.804297  ...  1.079918  1.099866  1.405821  1.530194   \n",
            "9   1.155531  1.677619  1.212996  ...  0.689915  1.580955  0.688477  0.856317   \n",
            "10  2.440837  0.454167  1.807404  ...  1.290290  0.680996  0.504858  0.816799   \n",
            "11  1.219390  0.823564  0.992662  ...  0.686597  1.409714  1.100107  0.964243   \n",
            "12  1.511450 -0.028687  1.066361  ...  0.899634  0.634640  1.314395  0.703091   \n",
            "13  0.861533  1.212974  0.566155  ...  1.212796  0.705594  0.500092  0.523914   \n",
            "\n",
            "         324       325       326       327       328       329  \n",
            "0   0.302746  0.361778  1.283911  0.261647  1.485219  1.103891  \n",
            "1   2.210615 -0.158565  0.736503  1.247386  1.574911  0.678303  \n",
            "2   1.294693  0.707821  0.586317  0.134039  0.931750  1.968716  \n",
            "3   1.761819  0.754702  0.243857  0.922130  0.645338  0.688940  \n",
            "4   1.295905  1.378697  0.806462  0.941957  1.280642  0.264961  \n",
            "5   1.038900 -0.630350  0.790833  0.928379  2.150385  0.894041  \n",
            "6   1.503612  0.262709  1.009300  1.310574  1.365101  0.612397  \n",
            "7   1.069715  0.349934  0.274726  0.406377  0.813246  1.603399  \n",
            "8   0.382250  0.629635  0.358398  1.117226  0.379075  1.052024  \n",
            "9   0.995328  1.561833  1.076569  1.099378  1.449431  1.038064  \n",
            "10  1.233263  0.874495  1.528042  1.249774  0.959221  0.981744  \n",
            "11  1.217342  1.395857  0.238840  0.974133  0.607520  1.454451  \n",
            "12  0.842759  1.234465  0.536462  0.127325 -0.128647  0.267300  \n",
            "13  1.111680  0.605359  0.497278  0.991628  0.461668  1.165640  \n",
            "\n",
            "[14 rows x 331 columns]\n",
            "   Unnamed: 0         0         1         2         3         4         5  \\\n",
            "0    3.049990  0.171445  1.066309  0.757294  0.582962  1.152191  1.248344   \n",
            "1    6.209121 -0.683053  0.166735  0.569135  1.773111  1.447399  0.692987   \n",
            "2    6.255150  0.065140  1.023787  0.549417  1.070653  1.031308  0.633897   \n",
            "3    2.201014 -0.307470  1.369897  0.799069  1.623284  1.158190  0.788806   \n",
            "4   10.437838 -0.842521  0.969741 -0.224265  0.364596  0.994792  0.254363   \n",
            "\n",
            "          6         7         8  ...       320       321       322       323  \\\n",
            "0  0.772380  1.243951  1.304503  ...  1.153243  0.937050  0.847393  0.734659   \n",
            "1  2.377130  0.502524  1.642669  ...  0.821163  1.480870  1.029034  0.740215   \n",
            "2  0.884055  0.774053  1.092351  ...  0.274626  0.201940  0.778140  1.174839   \n",
            "3  0.821856  0.604827  1.870345  ...  0.587348  1.954531  0.506248  0.805298   \n",
            "4  2.440837  0.454167  1.807404  ...  1.290290  0.680996  0.504858  0.816799   \n",
            "\n",
            "        324       325       326       327       328       329  \n",
            "0  1.761819  0.754702  0.243857  0.922130  0.645338  0.688940  \n",
            "1  1.069715  0.349934  0.274726  0.406377  0.813246  1.603399  \n",
            "2  1.503612  0.262709  1.009300  1.310574  1.365101  0.612397  \n",
            "3  1.294693  0.707821  0.586317  0.134039  0.931750  1.968716  \n",
            "4  1.233263  0.874495  1.528042  1.249774  0.959221  0.981744  \n",
            "\n",
            "[5 rows x 331 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add csv files\n",
        "\n",
        "import csv"
      ],
      "metadata": {
        "id": "-mhz3NkWlaRC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_csv_files(file1, file2, output_file):\n",
        "    merged_data = []\n",
        "\n",
        "    # Read the first CSV file\n",
        "    with open(file1, 'r') as csv_file1:\n",
        "        csv_reader1 = csv.reader(csv_file1)\n",
        "        merged_data.extend(list(csv_reader1))\n",
        "\n",
        "    # Read the second CSV file\n",
        "    with open(file2, 'r') as csv_file2:\n",
        "        csv_reader2 = csv.reader(csv_file2)\n",
        "        merged_data.extend(list(csv_reader2))\n",
        "\n",
        "    # Write the merged data to a new CSV file\n",
        "    with open(output_file, 'w', newline='') as csv_output:\n",
        "        csv_writer = csv.writer(csv_output)\n",
        "        csv_writer.writerows(merged_data)\n",
        "\n",
        "# Usage example\n",
        "file1 = r'/content/without_attack.csv'\n",
        "file2 = r'noisy_data.csv'\n",
        "output_file = 'merged.csv'\n",
        "merge_csv_files(file1, file2, output_file)"
      ],
      "metadata": {
        "id": "T4okN0c3lfKI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing a common row after adding both gauss noise attack and non gaussian files.\n",
        "def remove_csv_row(input_file, output_file, row_number):\n",
        "    # Read the CSV file\n",
        "    with open(input_file, 'r') as csv_file:\n",
        "        csv_reader = csv.reader(csv_file)\n",
        "        data = list(csv_reader)\n",
        "\n",
        "    # Remove the specified row\n",
        "    if row_number < len(data):\n",
        "        del data[row_number]\n",
        "\n",
        "    # Write the modified data back to the CSV file\n",
        "    with open(output_file, 'w', newline='') as csv_output:\n",
        "        csv_writer = csv.writer(csv_output)\n",
        "        csv_writer.writerows(data)\n",
        "\n",
        "# Usage example\n",
        "input_file = 'merged.csv'\n",
        "output_file = 'output.csv'\n",
        "row_number_to_remove = 15\n",
        "\n",
        "remove_csv_row(input_file, output_file, row_number_to_remove)\n",
        "out_file1 = pd.read_csv(r'output.csv')\n",
        "print(\"inputfile\\n\",out_file1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6sBbAEwl1OR",
        "outputId": "5f71bcf6-635f-4c1b-966f-5a908646d077"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputfile\n",
            "     Unnamed: 0         0         1         2         3         4         5  \\\n",
            "0     0.000000  0.000000  1.005513  1.000230  0.996058  0.994787  0.994405   \n",
            "1     1.000000  0.000000  0.990960  0.987148  0.982963  0.981680  0.981295   \n",
            "2     2.000000  0.000000  0.951800  0.950249  0.945989  0.944675  0.944281   \n",
            "3     3.000000  0.000000  0.967765  0.971844  0.967768  0.966495  0.966112   \n",
            "4     4.000000  0.000000  0.963105  0.966423  0.962317  0.961033  0.960647   \n",
            "5     5.000000  0.000000  0.944005  0.953005  0.948935  0.947650  0.947263   \n",
            "6     6.000000  0.000000  0.981871  0.990865  0.986739  0.985494  0.985119   \n",
            "7     7.000000  0.000000  0.983927  0.996208  0.992045  0.990830  0.990462   \n",
            "8     8.000000  0.000000  0.969115  0.980292  0.976149  0.974903  0.974527   \n",
            "9     9.000000  0.000000  0.956494  0.966900  0.962749  0.961484  0.961103   \n",
            "10   10.000000  0.000000  0.938260  0.947112  0.942969  0.941677  0.941287   \n",
            "11   11.000000  0.000000  0.950467  0.959343  0.955289  0.954011  0.953626   \n",
            "12   12.000000  0.000000  0.917528  0.925149  0.920966  0.919642  0.919244   \n",
            "13   13.000000  0.000000  0.928088  0.936246  0.932000  0.930691  0.930296   \n",
            "14    0.022548  0.731711  1.460631  1.181690  1.506552 -0.269626  0.827906   \n",
            "15    1.045936 -0.672639  1.479753  0.930949  1.620446  0.723002  0.400265   \n",
            "16    2.201014 -0.307470  1.369897  0.799069  1.623284  1.158190  0.788806   \n",
            "17    3.049990  0.171445  1.066309  0.757294  0.582962  1.152191  1.248344   \n",
            "18    3.992112 -0.322329  1.346721  0.627154  2.190766  1.833913  0.649574   \n",
            "19    4.097633 -0.718435  0.689104  0.690743  1.540620  0.576439  0.636848   \n",
            "20    6.255150  0.065140  1.023787  0.549417  1.070653  1.031308  0.633897   \n",
            "21    6.209121 -0.683053  0.166735  0.569135  1.773111  1.447399  0.692987   \n",
            "22    7.822304  0.379923  0.956333  0.944786  0.377043  1.040007  0.342155   \n",
            "23   10.103559  0.253373  1.419676  1.472139  0.859712  0.792344  0.754511   \n",
            "24   10.437838 -0.842521  0.969741 -0.224265  0.364596  0.994792  0.254363   \n",
            "25   11.333699  0.512575  0.844407 -0.103152  0.202188 -0.315183  0.735661   \n",
            "26   11.503851  0.604421  0.821326 -0.057625  0.721021  0.195318  1.089491   \n",
            "27   12.803756  0.178579  0.494271  1.209421  0.481537  0.679365  1.133506   \n",
            "\n",
            "           6         7         8  ...       320       321       322       323  \\\n",
            "0   0.994291  0.994257  1.004259  ...  0.989217  0.989077  0.989036  1.004424   \n",
            "1   0.981180  0.981145  0.989579  ...  0.976001  0.975861  0.975819  0.989821   \n",
            "2   0.944163  0.944128  0.950265  ...  0.938761  0.938617  0.938574  0.950606   \n",
            "3   0.965998  0.965964  0.966405  ...  0.960876  0.960736  0.960695  0.966619   \n",
            "4   0.960531  0.960497  0.961745  ...  0.955380  0.955239  0.955197  0.961957   \n",
            "5   0.947147  0.947113  0.942516  ...  0.941819  0.941678  0.941635  0.942767   \n",
            "6   0.985007  0.984973  0.980302  ...  0.980049  0.979912  0.979871  0.980624   \n",
            "7   0.990353  0.990320  0.982282  ...  0.985152  0.985018  0.984978  0.982498   \n",
            "8   0.974415  0.974381  0.967554  ...  0.969978  0.969841  0.969800  0.968060   \n",
            "9   0.960989  0.960956  0.954930  ...  0.956286  0.956147  0.956106  0.955386   \n",
            "10  0.941171  0.941136  0.936740  ...  0.935991  0.935849  0.935807  0.937066   \n",
            "11  0.953511  0.953476  0.948928  ...  0.947618  0.947477  0.947435  0.948840   \n",
            "12  0.919125  0.919089  0.916092  ...  0.913590  0.913444  0.913401  0.916265   \n",
            "13  0.930179  0.930143  0.926599  ...  0.925158  0.925014  0.924971  0.926948   \n",
            "14  0.277984  1.264880  0.296933  ...  1.575325  0.070288  1.749439  1.572800   \n",
            "15  0.434335  1.195689  0.175256  ...  0.910945  1.925933  1.258861  1.351098   \n",
            "16  0.821856  0.604827  1.870345  ...  0.587348  1.954531  0.506248  0.805298   \n",
            "17  0.772380  1.243951  1.304503  ...  1.153243  0.937050  0.847393  0.734659   \n",
            "18  0.473964  0.582532  0.483252  ...  0.261437 -0.118438  0.607778  0.990226   \n",
            "19  1.067320  2.049586  1.265614  ...  0.209931  1.167336  0.456188  1.041420   \n",
            "20  0.884055  0.774053  1.092351  ...  0.274626  0.201940  0.778140  1.174839   \n",
            "21  2.377130  0.502524  1.642669  ...  0.821163  1.480870  1.029034  0.740215   \n",
            "22  0.923363  0.533372  0.804297  ...  1.079918  1.099866  1.405821  1.530194   \n",
            "23  1.155531  1.677619  1.212996  ...  0.689915  1.580955  0.688477  0.856317   \n",
            "24  2.440837  0.454167  1.807404  ...  1.290290  0.680996  0.504858  0.816799   \n",
            "25  1.219390  0.823564  0.992662  ...  0.686597  1.409714  1.100107  0.964243   \n",
            "26  1.511450 -0.028687  1.066361  ...  0.899634  0.634640  1.314395  0.703091   \n",
            "27  0.861533  1.212974  0.566155  ...  1.212796  0.705594  0.500092  0.523914   \n",
            "\n",
            "         324       325       326       327       328       329  \n",
            "0   0.998431  0.993940  0.992549  0.992130  0.992005  0.991968  \n",
            "1   0.985280  0.980773  0.979369  0.978946  0.978820  0.978782  \n",
            "2   0.948252  0.943665  0.942226  0.941793  0.941663  0.941625  \n",
            "3   0.969954  0.965567  0.964174  0.963754  0.963628  0.963591  \n",
            "4   0.964520  0.960098  0.958693  0.958270  0.958143  0.958105  \n",
            "5   0.950936  0.946556  0.945150  0.944725  0.944598  0.944560  \n",
            "6   0.988945  0.984521  0.983159  0.982747  0.982624  0.982587  \n",
            "7   0.994158  0.989705  0.988375  0.987972  0.987851  0.987815  \n",
            "8   0.978571  0.974133  0.972770  0.972358  0.972234  0.972198  \n",
            "9   0.965070  0.960618  0.959234  0.958816  0.958691  0.958654  \n",
            "10  0.945097  0.940643  0.939228  0.938801  0.938673  0.938635  \n",
            "11  0.956894  0.952530  0.951131  0.950708  0.950581  0.950544  \n",
            "12  0.922993  0.918490  0.917040  0.916603  0.916472  0.916433  \n",
            "13  0.934298  0.929737  0.928304  0.927871  0.927742  0.927703  \n",
            "14  0.302746  0.361778  1.283911  0.261647  1.485219  1.103891  \n",
            "15  2.210615 -0.158565  0.736503  1.247386  1.574911  0.678303  \n",
            "16  1.294693  0.707821  0.586317  0.134039  0.931750  1.968716  \n",
            "17  1.761819  0.754702  0.243857  0.922130  0.645338  0.688940  \n",
            "18  1.295905  1.378697  0.806462  0.941957  1.280642  0.264961  \n",
            "19  1.038900 -0.630350  0.790833  0.928379  2.150385  0.894041  \n",
            "20  1.503612  0.262709  1.009300  1.310574  1.365101  0.612397  \n",
            "21  1.069715  0.349934  0.274726  0.406377  0.813246  1.603399  \n",
            "22  0.382250  0.629635  0.358398  1.117226  0.379075  1.052024  \n",
            "23  0.995328  1.561833  1.076569  1.099378  1.449431  1.038064  \n",
            "24  1.233263  0.874495  1.528042  1.249774  0.959221  0.981744  \n",
            "25  1.217342  1.395857  0.238840  0.974133  0.607520  1.454451  \n",
            "26  0.842759  1.234465  0.536462  0.127325 -0.128647  0.267300  \n",
            "27  1.111680  0.605359  0.497278  0.991628  0.461668  1.165640  \n",
            "\n",
            "[28 rows x 331 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transpose of the pandas data\n",
        "\n",
        "def transpose_csv(input_file, output_file):\n",
        "    # Read the CSV file\n",
        "    with open(input_file, 'r') as csv_file:\n",
        "        csv_reader = csv.reader(csv_file)\n",
        "        data = list(csv_reader)\n",
        "\n",
        "    # Convert the data to a NumPy array\n",
        "    data_array = np.array(data)\n",
        "\n",
        "    # Transpose the data\n",
        "    transposed_data = np.transpose(data_array)\n",
        "\n",
        "    # Write the transposed data to a new CSV file\n",
        "    with open(output_file, 'w', newline='') as csv_output:\n",
        "        csv_writer = csv.writer(csv_output)\n",
        "        csv_writer.writerows(transposed_data)\n",
        "\n",
        "# Usage example\n",
        "input_file1 = 'output.csv'\n",
        "output_file2 = 'output2.csv'\n",
        "\n",
        "transpose_csv(input_file1, output_file2)\n",
        "out_file = pd.read_csv(r'output2.csv')\n",
        "print(\"new input\", out_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuTMeBz0mFHI",
        "outputId": "9c64d09b-8659-4ba4-9aa7-0dab292f51b6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new input      Unnamed: 0         0         1         2         3         4         5  \\\n",
            "0             0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "1             1  1.005513  0.990960  0.951800  0.967765  0.963105  0.944005   \n",
            "2             2  1.000230  0.987148  0.950249  0.971844  0.966423  0.953005   \n",
            "3             3  0.996058  0.982963  0.945989  0.967768  0.962317  0.948935   \n",
            "4             4  0.994787  0.981680  0.944675  0.966495  0.961033  0.947650   \n",
            "..          ...       ...       ...       ...       ...       ...       ...   \n",
            "325         325  0.993940  0.980773  0.943665  0.965567  0.960098  0.946556   \n",
            "326         326  0.992549  0.979369  0.942226  0.964174  0.958693  0.945150   \n",
            "327         327  0.992130  0.978946  0.941793  0.963754  0.958270  0.944725   \n",
            "328         328  0.992005  0.978820  0.941663  0.963628  0.958143  0.944598   \n",
            "329         329  0.991968  0.978782  0.941625  0.963591  0.958105  0.944560   \n",
            "\n",
            "            6         7         8  ...  3.9921123202535855  4.097633243709772  \\\n",
            "0    0.000000  0.000000  0.000000  ...           -0.322329          -0.718435   \n",
            "1    0.981871  0.983927  0.969115  ...            1.346721           0.689104   \n",
            "2    0.990865  0.996208  0.980292  ...            0.627154           0.690743   \n",
            "3    0.986739  0.992045  0.976149  ...            2.190766           1.540620   \n",
            "4    0.985494  0.990830  0.974903  ...            1.833913           0.576439   \n",
            "..        ...       ...       ...  ...                 ...                ...   \n",
            "325  0.984521  0.989705  0.974133  ...            1.378697          -0.630350   \n",
            "326  0.983159  0.988375  0.972770  ...            0.806462           0.790833   \n",
            "327  0.982747  0.987972  0.972358  ...            0.941957           0.928379   \n",
            "328  0.982624  0.987851  0.972234  ...            1.280642           2.150385   \n",
            "329  0.982587  0.987815  0.972198  ...            0.264961           0.894041   \n",
            "\n",
            "     6.255150294404492  6.209120669372729  7.822304039470688  \\\n",
            "0             0.065140          -0.683053           0.379923   \n",
            "1             1.023787           0.166735           0.956333   \n",
            "2             0.549417           0.569135           0.944786   \n",
            "3             1.070653           1.773111           0.377043   \n",
            "4             1.031308           1.447399           1.040007   \n",
            "..                 ...                ...                ...   \n",
            "325           0.262709           0.349934           0.629635   \n",
            "326           1.009300           0.274726           0.358398   \n",
            "327           1.310574           0.406377           1.117226   \n",
            "328           1.365101           0.813246           0.379075   \n",
            "329           0.612397           1.603399           1.052024   \n",
            "\n",
            "     10.103559356411367  10.437837771826928  11.33369909103462  \\\n",
            "0              0.253373           -0.842521           0.512575   \n",
            "1              1.419676            0.969741           0.844407   \n",
            "2              1.472139           -0.224265          -0.103152   \n",
            "3              0.859712            0.364596           0.202188   \n",
            "4              0.792344            0.994792          -0.315183   \n",
            "..                  ...                 ...                ...   \n",
            "325            1.561833            0.874495           1.395857   \n",
            "326            1.076569            1.528042           0.238840   \n",
            "327            1.099378            1.249774           0.974133   \n",
            "328            1.449431            0.959221           0.607520   \n",
            "329            1.038064            0.981744           1.454451   \n",
            "\n",
            "     11.503851373518678  12.803755774087517  \n",
            "0              0.604421            0.178579  \n",
            "1              0.821326            0.494271  \n",
            "2             -0.057625            1.209421  \n",
            "3              0.721021            0.481537  \n",
            "4              0.195318            0.679365  \n",
            "..                  ...                 ...  \n",
            "325            1.234465            0.605359  \n",
            "326            0.536462            0.497278  \n",
            "327            0.127325            0.991628  \n",
            "328           -0.128647            0.461668  \n",
            "329            0.267300            1.165640  \n",
            "\n",
            "[330 rows x 29 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOW OUR FILE IS READY TO TRAIN THE CNN MODEL AND PREDICT THE 331st Day DATA.\n"
      ],
      "metadata": {
        "id": "IyOEqNuimUJL"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the pandas dataframe into numpy arrays\n",
        "# Data Preprocessing\n",
        "\n",
        "x = out_file.to_numpy()\n",
        "# x = np.transpose(x)\n",
        "print(x)\n",
        "print(\"idk\",x.shape)\n",
        "index = int(len(x) * .80)\n",
        "labels = np.concatenate((np.zeros(len(x)//2), np.ones(len(x)//2)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9lX_tj6meIl",
        "outputId": "8e028f35-36fa-43fb-ca4d-a2601bee376b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  5.12575276e-01\n",
            "   6.04420706e-01  1.78578623e-01]\n",
            " [ 1.00000000e+00  1.00551258e+00  9.90960245e-01 ...  8.44406560e-01\n",
            "   8.21326224e-01  4.94270764e-01]\n",
            " [ 2.00000000e+00  1.00022977e+00  9.87148260e-01 ... -1.03151537e-01\n",
            "  -5.76248067e-02  1.20942129e+00]\n",
            " ...\n",
            " [ 3.27000000e+02  9.92130384e-01  9.78946378e-01 ...  9.74132788e-01\n",
            "   1.27325341e-01  9.91628123e-01]\n",
            " [ 3.28000000e+02  9.92004980e-01  9.78819799e-01 ...  6.07520146e-01\n",
            "  -1.28647441e-01  4.61667734e-01]\n",
            " [ 3.29000000e+02  9.91967601e-01  9.78782069e-01 ...  1.45445079e+00\n",
            "   2.67299740e-01  1.16564005e+00]]\n",
            "idk (330, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Test Splitting using Sklearn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "trainX, testX, trainy, testy = train_test_split(x,labels,test_size=0.2,random_state=42)\n",
        "print(\"labels\\n\",labels)\n",
        "\n",
        "# data preprocessing to adjust dimentional cardinality\n",
        "testX = np.expand_dims(testX,axis=-1)\n",
        "trainX = np.expand_dims(trainX,axis=-1)\n",
        "print((trainX.shape, trainy.shape), (testX.shape,testy.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpDVEroRmp7e",
        "outputId": "357a0c18-0adf-4f8a-ff7b-6fda9cbc26ac"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "((264, 29, 1), (264,)) ((66, 29, 1), (66,))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# MODEL SELECTION\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import Sequential\n",
        "from keras.models import Sequential\n",
        "from keras.layers import * # dense faltten dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.utils import to_categorical\n",
        "model = Sequential()\n",
        "\n",
        "# Define the 1D CNN model\n",
        "\n",
        "model.add(Conv1D(16, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "GMJCdC_JnCZf"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(trainX, trainy, epochs=10, batch_size=32, validation_data=(testX, testy))\n",
        "loss, accuracy = model.evaluate(testX, testy, batch_size=32, verbose=0)\n",
        "print(f'Test loss: {loss:.4f}')\n",
        "print(f'Test accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Lh459cVnJBm",
        "outputId": "c88a539e-4272-40cf-afcb-9e5875d218b1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "9/9 [==============================] - 1s 27ms/step - loss: 3.0981 - accuracy: 0.5227 - val_loss: 2.6747 - val_accuracy: 0.5455\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2584 - accuracy: 0.5417 - val_loss: 1.8357 - val_accuracy: 0.5606\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4723 - accuracy: 0.5985 - val_loss: 1.0392 - val_accuracy: 0.5909\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7321 - accuracy: 0.6629 - val_loss: 0.4368 - val_accuracy: 0.7879\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3492 - accuracy: 0.8447 - val_loss: 0.3133 - val_accuracy: 0.9242\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3545 - accuracy: 0.9167 - val_loss: 0.2891 - val_accuracy: 0.9394\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.9432 - val_loss: 0.2754 - val_accuracy: 0.8788\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.2748 - accuracy: 0.8902 - val_loss: 0.2588 - val_accuracy: 0.8788\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2514 - accuracy: 0.9167 - val_loss: 0.2365 - val_accuracy: 0.9545\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2365 - accuracy: 0.9432 - val_loss: 0.2251 - val_accuracy: 0.9697\n",
            "Test loss: 0.2251\n",
            "Test accuracy: 0.9697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the testing set\n",
        "y_pred = model.predict(testX)\n",
        "print(\"predicted value\")\n",
        "# Binary Classification\n",
        "import array as arr\n",
        "bin_arr = arr.array('i',[])\n",
        "for i in y_pred:\n",
        "    # print(i,end=\" - \")\n",
        "    if(i<0.5):\n",
        "        bin_arr.append(0)\n",
        "    else:\n",
        "        bin_arr.append(1)\n",
        "for i in range(len(y_pred)):\n",
        "    print(y_pred[i],\" - \",bin_arr[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_IIlVaKnVmh",
        "outputId": "9112abc8-fa90-4910-a377-24a21f3df9db"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n",
            "predicted value\n",
            "[0.04869715]  -  0\n",
            "[0.598692]  -  1\n",
            "[0.47212374]  -  0\n",
            "[0.10901702]  -  0\n",
            "[0.20421302]  -  0\n",
            "[0.22218786]  -  0\n",
            "[0.14560974]  -  0\n",
            "[0.9772072]  -  1\n",
            "[0.97657394]  -  1\n",
            "[0.81609154]  -  1\n",
            "[0.58825856]  -  1\n",
            "[0.98453754]  -  1\n",
            "[0.16412993]  -  0\n",
            "[0.11636473]  -  0\n",
            "[0.89866215]  -  1\n",
            "[0.4110474]  -  0\n",
            "[0.320507]  -  0\n",
            "[0.98162025]  -  1\n",
            "[0.18256141]  -  0\n",
            "[0.6134953]  -  1\n",
            "[0.06712074]  -  0\n",
            "[0.08079048]  -  0\n",
            "[0.29310915]  -  0\n",
            "[0.9724103]  -  1\n",
            "[0.06971097]  -  0\n",
            "[0.31243178]  -  0\n",
            "[0.95624846]  -  1\n",
            "[0.9326513]  -  1\n",
            "[0.9434137]  -  1\n",
            "[0.87009656]  -  1\n",
            "[0.9417771]  -  1\n",
            "[0.9608557]  -  1\n",
            "[0.8186451]  -  1\n",
            "[0.87754214]  -  1\n",
            "[0.90783364]  -  1\n",
            "[0.9686786]  -  1\n",
            "[0.6654216]  -  1\n",
            "[0.12792973]  -  0\n",
            "[0.10149368]  -  0\n",
            "[0.11278702]  -  0\n",
            "[0.5638348]  -  1\n",
            "[0.96267897]  -  1\n",
            "[0.5411731]  -  1\n",
            "[0.27701062]  -  0\n",
            "[0.93742925]  -  1\n",
            "[0.11635026]  -  0\n",
            "[0.8363227]  -  1\n",
            "[0.97124195]  -  1\n",
            "[0.45726466]  -  0\n",
            "[0.41009802]  -  0\n",
            "[0.15368073]  -  0\n",
            "[0.05654031]  -  0\n",
            "[0.1464403]  -  0\n",
            "[0.43458655]  -  0\n",
            "[0.03791744]  -  0\n",
            "[0.10930669]  -  0\n",
            "[0.4620234]  -  0\n",
            "[0.94245327]  -  1\n",
            "[0.9569199]  -  1\n",
            "[0.57629055]  -  1\n",
            "[0.02929483]  -  0\n",
            "[0.67176497]  -  1\n",
            "[0.6206155]  -  1\n",
            "[0.8201735]  -  1\n",
            "[0.11973105]  -  0\n",
            "[0.94939077]  -  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and test accuracy\n",
        "loss, accuracy = model.evaluate(testX, testy, batch_size=32, verbose=0)\n",
        "print(f'Test loss: {loss:.4f}')\n",
        "print(f'Test accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED2u20WboJaH",
        "outputId": "3954be8b-4767-491e-8201-2d8dc37cb80d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.2251\n",
            "Test accuracy: 0.9697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting Model for 331st day data\n",
        "x_test = x[329:330,:-1]\n",
        "print(x_test)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "y_predict = model.predict(x_test)\n",
        "print(\"predicted value\")\n",
        "# for i in y_predict:\n",
        "#     print(i,end=\" - \")\n",
        "#     if(i<0.5):\n",
        "#         print(0)\n",
        "#     else:\n",
        "#         print(1)\n",
        "bin_arr2 = arr.array('i',[])\n",
        "for i in y_predict:\n",
        "    if(i<0.5):\n",
        "        bin_arr2.append(0)\n",
        "    else:\n",
        "        bin_arr2.append(1)\n",
        "for i in range(len(y_predict)):\n",
        "    print(y_predict[i],\" - \",bin_arr2[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moQsfw0SoRK4",
        "outputId": "ab3b6211-7ad8-4d82-b674-7824acfe031d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.29000000e+02 9.91967601e-01 9.78782069e-01 9.41624773e-01\n",
            "  9.63590959e-01 9.58104956e-01 9.44560005e-01 9.82587213e-01\n",
            "  9.87815484e-01 9.72197678e-01 9.58653650e-01 9.38634629e-01\n",
            "  9.50543522e-01 9.16432608e-01 9.27703202e-01 1.10389117e+00\n",
            "  6.78303409e-01 1.96871641e+00 6.88940215e-01 2.64961326e-01\n",
            "  8.94041168e-01 6.12396944e-01 1.60339904e+00 1.05202410e+00\n",
            "  1.03806396e+00 9.81743652e-01 1.45445079e+00 2.67299740e-01]]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "predicted value\n",
            "[0.9781409]  -  1\n"
          ]
        }
      ]
    }
  ]
}